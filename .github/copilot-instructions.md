```instructions
# í•œêµ­ì–´ (Korean) / English

---

# ðŸ‡°ðŸ‡· í•µì‹¬ ê·œì¹™
- í”„ë¡œì íŠ¸ëª…: otel-langfuse
- LangGraph ê¸°ë°˜ Teacher-Student í€´ì¦ˆ ì‹œìŠ¤í…œ
- OpenTelemetry + Traceloopì„ í†µí•œ LLM observability
- Azure AI Evaluation SDK (í’ˆì§ˆ) + Azure AI Content Safety (ì•ˆì „ì„±)ë¥¼ í†µí•œ ìžë™ í‰ê°€
- FastAPIë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ ì„œë²„ êµ¬ì¶•
- Azure OpenAI (GPT-4o) ì‚¬ìš©

## Architecture
```mermaid
flowchart TB
    subgraph App["LangGraph App"]
        FastAPI["FastAPI Server :8000"]
        LangGraph["LangGraph\nTeacher-Student"]
        Traceloop["Traceloop SDK"]
        BGEval["eval_background.py"]
        AzureOAI["Azure OpenAI GPT-4o"]
        
        FastAPI --> LangGraph
        LangGraph --> AzureOAI
        Traceloop -.->|auto instrument| LangGraph
        FastAPI --> BGEval
    end
    
    subgraph K8s["Kubernetes"]
        OTelCollector["OTel Collector :4317"]
        Langfuse["Langfuse"]
    end
    
    subgraph Observability["Azure Observability"]
        AppInsights["Application Insights"]
        Grafana["Managed Grafana"]
    end
    
    subgraph Evaluation["Evaluation (Async + Batch)"]
        EvalScript["evaluation.py"]
        AIEval["Azure AI Evaluation\n(Fluency, QA)"]
        ContentSafety["Azure AI Content Safety\n(Violence, Sexual, etc.)"]
    end
    
    Traceloop -->|OTLP/gRPC| OTelCollector
    OTelCollector -->|OTLP/HTTP| Langfuse
    OTelCollector -->|Azure Monitor| AppInsights
    BGEval -->|Eval Results| AppInsights
    AppInsights --> Grafana
    AppInsights -->|Query Traces| EvalScript
    EvalScript -->|Quality| AIEval
    EvalScript -->|Safety| ContentSafety
    EvalScript -->|Store Results| AppInsights
```

## í”„ë¡œì íŠ¸ êµ¬ì¡°
```
otel-langfuse/
â”œâ”€â”€ main.py              # FastAPI ì„œë²„ + OpenTelemetry ì´ˆê¸°í™”
â”œâ”€â”€ graph.py             # LangGraph ì›Œí¬í”Œë¡œìš° (Teacher-Student í€´ì¦ˆ)
â”œâ”€â”€ eval_background.py   # ë¹„ë™ê¸° ë°±ê·¸ë¼ìš´ë“œ í‰ê°€ (ìš”ì²­ë§ˆë‹¤ ìžë™ ì‹¤í–‰)
â”œâ”€â”€ evaluation.py        # Azure AI Evaluation ë°°ì¹˜ íŒŒì´í”„ë¼ì¸
â”œâ”€â”€ config.py            # í™˜ê²½ì„¤ì • ë¡œë“œ (.env)
â”œâ”€â”€ pyproject.toml       # Python ì˜ì¡´ì„± (uv)
â”œâ”€â”€ .env                 # í™˜ê²½ë³€ìˆ˜ (git ignore)
â”œâ”€â”€ evaluation_results/  # í‰ê°€ ê²°ê³¼ ì €ìž¥ ë””ë ‰í† ë¦¬
â”‚   â”œâ”€â”€ evaluation_data.jsonl
â”‚   â”œâ”€â”€ quality_evaluation_result.json
â”‚   â”œâ”€â”€ safety_evaluation_result.json
â”‚   â””â”€â”€ evaluation_metrics.json
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html       # ì›¹ UI
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css        # ìŠ¤íƒ€ì¼ì‹œíŠ¸
â””â”€â”€ k8s/
    â”œâ”€â”€ langfuse-values.yaml           # Langfuse Helm values
    â”œâ”€â”€ otel-collector-values.yaml     # OTel Collector Helm values
    â””â”€â”€ azure-grafana-langgraph.json   # Azure Managed Grafana ëŒ€ì‹œë³´ë“œ (v2)
```

## ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒ
- **LangGraph**: Multi-Agent ì›Œí¬í”Œë¡œìš°
- **LangChain OpenAI**: Azure OpenAI ì—°ë™
- **Traceloop SDK**: LLM input/output ìžë™ ê³„ì¸¡
- **OpenTelemetry**: ë¶„ì‚° íŠ¸ë ˆì´ì‹±
- **Azure AI Evaluation SDK**: í’ˆì§ˆ í‰ê°€ (Fluency, QA)
- **Azure AI Content Safety**: ì•ˆì „ì„± í‰ê°€ (Violence, Sexual, SelfHarm, Hate)
- **FastAPI**: ì›¹ í”„ë ˆìž„ì›Œí¬

## í™˜ê²½ë³€ìˆ˜ (.env)
```bash
# Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# OpenTelemetry
OTEL_EXPORTER_OTLP_ENDPOINT=http://20.214.217.93:4317

# Application Insights (Evaluation ë°ì´í„° ì¿¼ë¦¬ìš©)
APP_INSIGHTS_WORKSPACE_ID=your-workspace-id
APP_INSIGHTS_CONNECTION_STRING=InstrumentationKey=...

# Azure AI Content Safety (ì•ˆì „ì„± í‰ê°€ìš©)
AZURE_CONTENT_SAFETY_ENDPOINT=https://your-endpoint.cognitiveservices.azure.com/
AZURE_CONTENT_SAFETY_KEY=your-key
```

## ê°œë°œí™˜ê²½
- Python 3.10 ì´ìƒ
- uv íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € ì‚¬ìš©
- ì˜ì¡´ì„± ì„¤ì¹˜: `uv sync`
- ì„œë²„ ì‹¤í–‰: `.\.venv\Scripts\Activate.ps1; python main.py`
- ë°°ì¹˜ í‰ê°€ ì‹¤í–‰: `uv run python evaluation.py --hours 24 --limit 100`
- ì‹¤ì‹œê°„ í‰ê°€: ì„œë²„ ì‹¤í–‰ ì‹œ ë§¤ ìš”ì²­ë§ˆë‹¤ ë¹„ë™ê¸° ìžë™ ì‹¤í–‰ (eval_background.py)

## Evaluation í‰ê°€ í•­ëª©
- **í’ˆì§ˆ í‰ê°€** (Azure AI Evaluation SDK)
  - Fluency: ì‘ë‹µì˜ ìœ ì°½ì„± (1-5ì )
  - QA: Coherence, Relevance, Groundedness
- **ì•ˆì „ì„± í‰ê°€** (Azure AI Content Safety)
  - Violence: í­ë ¥ì„± (0-6ì , 0=ì•ˆì „)
  - Sexual: ì„±ì  ì½˜í…ì¸ 
  - SelfHarm: ìží•´ ê´€ë ¨
  - HateUnfairness: í˜ì˜¤/ì°¨ë³„

## Grafana ëŒ€ì‹œë³´ë“œ íŒ¨ë„
1. **Quality Evaluation Scores**: Fluency, Coherence, Relevance, Groundedness
2. **Safety Evaluation Scores**: Violence, Sexual, SelfHarm, HateUnfairness
3. **Quality Score Trends**: ì‹œê°„ë³„ í’ˆì§ˆ ì ìˆ˜ ì¶”ì´
4. **Safety Score Trends**: ì‹œê°„ë³„ ì•ˆì „ì„± ì ìˆ˜ ì¶”ì´
5. **Evaluation Results Detail**: ê°œë³„ í‰ê°€ ê²°ê³¼ í…Œì´ë¸”

## ëŒ€í™” ê·œì¹™
- ë°˜ë“œì‹œ í•œêµ­ì–´ë§Œ ì‚¬ìš©
- ì´ëª¨ì§€ ìµœì†Œí™”
- ì™„ë£Œì‹œ "ì™„ë£Œ" ë¼ê³  ëŒ€ë‹µ

---

# ðŸ‡ºðŸ‡¸ Core Rules
- Project Name: otel-langfuse
- LangGraph-based Teacher-Student Quiz System
- LLM observability via OpenTelemetry + Traceloop
- Automated evaluation with Azure AI Evaluation SDK (Quality) + Azure AI Content Safety (Safety)
- Web server built with FastAPI
- Uses Azure OpenAI (GPT-4o)

## Architecture
```mermaid
flowchart TB
    subgraph App["LangGraph App"]
        FastAPI["FastAPI Server :8000"]
        LangGraph["LangGraph\nTeacher-Student"]
        Traceloop["Traceloop SDK"]
        BGEval["eval_background.py"]
        AzureOAI["Azure OpenAI GPT-4o"]
        
        FastAPI --> LangGraph
        LangGraph --> AzureOAI
        Traceloop -.->|auto instrument| LangGraph
        FastAPI --> BGEval
    end
    
    subgraph K8s["Kubernetes"]
        OTelCollector["OTel Collector :4317"]
        Langfuse["Langfuse"]
    end
    
    subgraph Observability["Azure Observability"]
        AppInsights["Application Insights"]
        Grafana["Managed Grafana"]
    end
    
    subgraph Evaluation["Evaluation (Async + Batch)"]
        EvalScript["evaluation.py"]
        AIEval["Azure AI Evaluation\n(Fluency, QA)"]
        ContentSafety["Azure AI Content Safety\n(Violence, Sexual, etc.)"]
    end
    
    Traceloop -->|OTLP/gRPC| OTelCollector
    OTelCollector -->|OTLP/HTTP| Langfuse
    OTelCollector -->|Azure Monitor| AppInsights
    BGEval -->|Eval Results| AppInsights
    AppInsights --> Grafana
    AppInsights -->|Query Traces| EvalScript
    EvalScript -->|Quality| AIEval
    EvalScript -->|Safety| ContentSafety
    EvalScript -->|Store Results| AppInsights
```

## Project Structure
```
otel-langfuse/
â”œâ”€â”€ main.py              # FastAPI server + OpenTelemetry initialization
â”œâ”€â”€ graph.py             # LangGraph workflow (Teacher-Student Quiz)
â”œâ”€â”€ eval_background.py   # Async background evaluation (auto per request)
â”œâ”€â”€ evaluation.py        # Azure AI Evaluation batch pipeline
â”œâ”€â”€ config.py            # Configuration loader (.env)
â”œâ”€â”€ pyproject.toml       # Python dependencies (uv)
â”œâ”€â”€ .env                 # Environment variables (git ignored)
â”œâ”€â”€ evaluation_results/  # Evaluation results directory
â”‚   â”œâ”€â”€ evaluation_data.jsonl
â”‚   â”œâ”€â”€ quality_evaluation_result.json
â”‚   â”œâ”€â”€ safety_evaluation_result.json
â”‚   â””â”€â”€ evaluation_metrics.json
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html       # Web UI
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css        # Stylesheet
â””â”€â”€ k8s/
    â”œâ”€â”€ langfuse-values.yaml           # Langfuse Helm values
    â”œâ”€â”€ otel-collector-values.yaml     # OTel Collector Helm values
    â””â”€â”€ azure-grafana-langgraph.json   # Azure Managed Grafana dashboard (v2)
```

## Tech Stack
- **LangGraph**: Multi-Agent workflow
- **LangChain OpenAI**: Azure OpenAI integration
- **Traceloop SDK**: LLM input/output auto-instrumentation
- **OpenTelemetry**: Distributed tracing
- **Azure AI Evaluation SDK**: Quality evaluation (Fluency, QA)
- **Azure AI Content Safety**: Safety evaluation (Violence, Sexual, SelfHarm, Hate)
- **FastAPI**: Web framework

## Environment Variables (.env)
```bash
# Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# OpenTelemetry
OTEL_EXPORTER_OTLP_ENDPOINT=http://20.214.217.93:4317

# Application Insights (for Evaluation data query)
APP_INSIGHTS_WORKSPACE_ID=your-workspace-id
APP_INSIGHTS_CONNECTION_STRING=InstrumentationKey=...

# Azure AI Content Safety (for Safety evaluation)
AZURE_CONTENT_SAFETY_ENDPOINT=https://your-endpoint.cognitiveservices.azure.com/
AZURE_CONTENT_SAFETY_KEY=your-key
```

## Development
- Python 3.10+
- Use uv package manager
- Install dependencies: `uv sync`
- Run server: `.\.venv\Scripts\Activate.ps1; python main.py`
- Run batch evaluation: `uv run python evaluation.py --hours 24 --limit 100`
- Real-time evaluation: Auto-runs per request when server is running (eval_background.py)

## Evaluation Metrics
- **Quality Evaluation** (Azure AI Evaluation SDK)
  - Fluency: Response fluency (1-5 score)
  - QA: Coherence, Relevance, Groundedness
- **Safety Evaluation** (Azure AI Content Safety)
  - Violence: Violence level (0-6, 0=safe)
  - Sexual: Sexual content
  - SelfHarm: Self-harm related
  - HateUnfairness: Hate/discrimination

## Grafana Dashboard Panels
1. **Quality Evaluation Scores**: Fluency, Coherence, Relevance, Groundedness
2. **Safety Evaluation Scores**: Violence, Sexual, SelfHarm, HateUnfairness
3. **Quality Score Trends**: Quality score trends over time
4. **Safety Score Trends**: Safety score trends over time
5. **Evaluation Results Detail**: Individual evaluation results table

## Conversation Rules
- Use English for global presentation
- Minimize emojis
- Reply "Done" when completed
```


